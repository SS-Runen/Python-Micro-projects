++++++++++++++++++
General Guidelines

- When testing a formula or procedure, try the process using some input. For equations, try to find a trend in the results relative to the input. For ML algorithms, run limited tests on groups or sets with at least thirty samples. Depending on the situation, a control may be needed or the same data has to be used for different processes.

- Test validation and logic-checking are mandatory. For complicated functions or classes, more granular or step-by-step checks may be necessary. This applies to both math and code.

- To start Spyder in Ubuntu Linux:
conda activate spyder-env
spyder

Here, "spyder-env" is the name of your Conda environment. This is the default name and it may be changed.

- A plugin is needed to open and edit notebooks in Spyder:
conda install spyder-notebook -c conda-forge

- Until there is a proven need for other programming languages or libraries, Python and its libraries will be the primary ML and AI tools. Julia, R, and SQL may be learned based on what the problem or research project requires. For now, the focus is on transferrable fundamentals of math, statistics, AI, and ML.

+++++++++++++++++++++++++++++++++++
Matrix Operations and Vectorization

- The dot product of two vectors x and y is equivalent to the dot product of transpose(x) and y.

- You may only perform a dot product on vectors with the same length.

@@@
Matrix Multiplication Rules

- To multiply matrices, the first matrix must have the same number of columns (vertical vectors) as the other matrix' rows. E.g. three by two and two by four. To multiply a twelve by n and m by twelve matrix, the m by twelve matrix has to be the first input of the operation. This is a side-effect of the dot-product rule for multiplying vectors.

- The result of a matrix dot product will have the same number of rows as the first matrix and the same number of columns as the second.

- In general, matrix multiplication is NOT commutative. The order of the matrices is significant in matrix multiplication. Only certain edge cases result in commutative matrix multiplications.

++++++++++++++++++++++++++++++++
Basic Artificial Neural Networks

@@@
Convolutional Neural Network
- A Convolutional Nueral Network (CNN) has units or neurons that only process part of the previous layer's output. These units will only process a section of the input data. It can compute results faster and reduce overfitting. The data or input for each neuron may overlap with other neurons. For images, it could mean overlapping coverage of an area. For time-series data, the time boundaries of the neurons may overlap. There, the next neuron has some idea of earlier or later data.

++++++++++++++++
Model Evalutaion

@@@
Skewed Data Sets
- For data sets with isolated but important cases, plain accuracy is not a good metric. For example, rare medical conditions have be diagnosed accurately even if their input values are outliers. For continuous output, the input data where the model has a high error metric should be analyzed, whether thru categorization or statistical analysis.

- Precision: Precision refers to the ratio of correct positive predictions to total positive predictions. P(True|PredictedTrue).
Precision = ( true_positives / (true_positive_predictions + false_positive_predictions)).

- Recall: Recall is the ratio of correctly predicted positives and actual positives. True positives vs. actual positives.
Recall = true_positives / true_positives + false_negatives.

- F1 Score. This calculation takes a weighted average where the smaller value's effect is increased. This is better at measuring precision vs. recall since if either one is high, it can "hide" defects. The F1 score equation may be referred to as the "harmonic mean of precision and recall (P and R)."
F1 = 1 / (0.5 * ((1/Precision) + (1/Recall)))
Alternative:
F1 = 2 * ((P*R) / (P+R)) 

++++++++++++++
Decision Trees

- When deciding on criteria to split a node, maximize the purity or homogenity of the split groups. The increase in purity is referred to as "information gain."

- Entropy
E = -p1 log2(p1) - (1 - p1)log2(1-p1)
where:
p1 = Proportion of true or positive labels.

The logarithm has a base of two so that the output is always between zero and one. Entropy is used to measure purity. The higher the entropy, the more mixed or non-homogenous the split.

- Entropy is best used with a weighted average or coefficient. A group with few examples and high purity could skew the results. For each decision node, multiply the proportion of input samples per group with the group entropy. Add the two results to get the overall node entropy.

- To calculate the information gain/entropy reduction for decision nodes (nodes beyond the root node), find the difference between the entropy of the root node and the entropy of the decision node. Information gain may be a better metric for split quality than plain entropy.

Information gain from a node:
IG = H(p1r) - (wl * H(p1l) + wr * H(p1r))
where:

H(p1r) = Entropy of input before splitting at the node. The input here is the proportion of positively labelled data.
wl = Proportion of input split into the left node.
wr = Proportion of input split into the right node.
p1l = Proportion of positively labeled examples in the left node.
H(p1l) = Entropy of left split.
p1r = Proportion of positively labeled examples in the right node.
H(p1r) = Entropy of right split.

- When using one-hot encoding on a decision tree, create k new features/columns for k number of features, not k-1 for linear regression dummy values.

- When splitting continuous values, use the information gain to pick a threshold. Other analysis methods may also be used as comparison or to complement the analysis. The central tendencies of each group or normal distribution thresholds are good points to consider.

- The same feature may be used as the split criteria in both left and right sides.

- When using a decision tree to output a continuous value, reduce the total weighted average variance of the target value for the split groups. The reduction in variance may be used as a split quality metric. The greater the reduction in variance, the better the split.

- A single tree is very sensitive to changes in data, whether the input is categorical or continuous. Decision trees are best used together as decision tree ensembles. Different splits may be created based on multiple samplings with replacement. The conventional number of decision trees in an ensemble is around one hundred.

- Randomizing the subset of features to be used as candidates for split criteria increases accuracy. Out of n features, choose a set of k features as candidates for split criteria. The value of k should be less than n. This forces the exploration of different possible variations in the data.

XGBoost
- Part of XGBoost is a mechanism to increase the likelihood that misclassified samples will be picked during input sampling. XGBoost (Extreme Gradient Boosting) also has built-in regularization, though input may still need to be normalized.

- In general, decision trees work well with tabular data. The input data and prediction values may be categorical or continuous. Decision trees perform poorly on unstructured data such as text, images, and audio. Decision trees are usually faster to train compared to neural networks with similar performance. Small sections of decision trees might be human-readable.

* Neural networks may also do well with structured, unstructured, and mixed data. Transfer learning is not applicable to decision trees. As of 2023, neural networks are easier to string together than decision trees.

++++++++++
Clustering

@@@
K-means Clustering
- K-means clustering initializes k clusters and assigns data points based on their distance or "difference" compared to the cluster. Next, k-means will assign the centroid values to the average of each parameter using the current members of the cluster. K-means will minimize the distance or "distortion" within clusters by adjusting the centroid.

K-means Cost Function, a.k.a Distortion Function:
J(c1...cm, μ1...,μk) = (1/m)*(Σ||xi - μ(c^i)||^2

where:
c1...cm = Clusters 1 to m.
μ1...,μk = Centroids 1 to k corresponding to clusters 1 to m.
xi = Input data x at index i.
μ(c^i) = Notation for cluster centroid to which xi is assigned.

Initializing K-means
- Picking one random data point as the value for each data point may help avoid empty clusters. Points may also be selected by sorting the data and selecting data points at certain intervals.

- Running multiple trials of K-means is a viable option. If there are multiple results, pick the one with the lowest cost function J(c1...cm, μ1...,μk).

- Choosing k-clusters to minimize J does not give the best number of clusters. It usually gives the highest possible number of clusters without increasing J, not necessarily the most appropriate number of clusters. Minimizing J does not guarantee a truly significant or important difference between clusters. Manual data analysis and domain knowledge have to be included in the process to pick the number of clusters.

@@@
Anomaly Detection

Density Estimation
- One step of density estimation is to estimate the probability of certain outputs. The input and output may be vectors.

Gaussian/Normal Distribution
- The area of probabilities under the curve of a normal distribution is always equal to one.

p(x) = 1/sqrt(2πσ) * e^(-(x-μ)^2/2σ^2)
p(vector(x)) = p(x1;μ1,σ1^2) *...p(xn;μn,σn^2)
or
p(vector(x)) = j=1Πn p(xj;μj,σj^2)  

The assumption here is that the features are independent of each other.

- F1 scores, precision, and recall may also be used to evaluate model performance. The training, cross-validation and test sets should be representative of real data. Precision = ( true_positives / (true_positive_predictions + false_positive_predictions)). Recall = true_positives / true_positives + false_negatives. In anomaly detection, it is safer to only use a test set and training set, instead of a training, cross-validation, and test set. This should only be done if there is not enough data for a cross-validation and test set. Based on the results, adjust the cut-off parameter ε.

@@@
Unsupervised vs. Supervised Anomaly Detection

- It is complicated to choose between unsupervised anomaly detection and supervised machine learning for anomaly detection. If there is a very small amount of positive or anomalous samples, anomaly detection may be a better candidate.

- If there are several classes or significant diversity among a small sample of positive or negative samples, anomaly detection is more appropriate. This helps to guard against overfiting or failures to detect new kinds of anomalies. When future anomalies are likely to be significantly different from past samples, unsupervised anomaly detection is more effective.

@@@
Feature Selection for Anomaly Detection

- Make sure your features are normally distributed or "Gaussian." Features may also be transformed or engineered into Gaussian features. E.g. computing the logarithm of a skewed feature to make it more similar to the normal distribution. You may use log(x) or log(x + c) where c is an arbitrary constant. Plotting a histogram of the data is a valid check for normal distribution. In case of zeroes in x, add an extremely small decimal to x before getting the logarithm.

- Statistical analysis and other measures of normality may be used. Examples:
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6350423/

- Make sure that any transformations done to the training set is also done to the cross-validation and testing sets. If the p(x) for a known anomaly is high above the threshold, a new feature, engineered feature, or transformation may be needed. Sometimes, the threshold ε has to be adjusted.

+++++++++++++++++++
Recommender Systems

- If accurate product descriptions or parameters are available, it is possible to train a model with different parameters for each user or user class. Refer to the spreadsheet for the equation: Advanced Learning Algorithms - A. Ng. Here, linear regression is used to predict a rating for each user.

@@@
Collaborative Filtering
- Multiple vectors of user features corresponding to vectors of product features are used to learn parameters for future users and products. In the example, a vector containing viewer ratings for each movie is used with a vector of movie characteristics.

- To solve for product features (x) that predict target user feedback for a product, e.g. ratings (y or vector y), multiple vectors of known user features or feedback (w) corresponding to the vector of product characteristics (x) will be used. The model will calculate several predicted product feedback vectors. The average squared distance (Σy_pred / n_samples) between the calculated product feedback (dot_product(w, x)) and actual feedback y is used to calculate error. The derivatives with respect to product features x will be used to calculate product characteristic parameters (w) for each user. The vector (w) can be used in a dot product operation with user features (x) to predict user feedback for a product (y or vector y).

- Given multiple product characteristic/feature vectors x1...xn, the possible user feedback y for a product may be calculated. The average distance between calculated user feedback and actual user feedback will be used to calculate error and minimize the cost function output. The end result is a vector of user features (w) for product features (x) that may be used to predict user feedback (e.g. movie rating) for certain product features x.

- Both the algorithms above require one model per user or one model per product. The cost functions to learn user characteristics (w) and product characteristics (x) may be merged. User parameters (w1...wn) for a specific product (x) and product parameters (x1...xn) will be used for collaborative filtering.

- You may take partial derivatives relative to all parameters w, x, and b. Gradient descent may be used to update all of the parameters. Collaborative filtering relies on existing product and user matches to guide the parameter adjustments in case of gaps.

- Mean normalization may be used to prevent erroneous predictions for products or users without any data. For a user who has not interacted with any product, the prediction will be zero or undefined without mean normalization. To perform mean normalization, subtract the mean of a feature from each feature input value. After predicting a value, add the mean back. The mean will be used in place of zero or undefined predictions. 

- Strictly speaking, "normalization" means to recenter and re-scale our data such that is between 0 and 1 or -1 and 1 (Machine Learning Mastery). Normalized data can have multiple meanings. In most cases, when you normalize data you eliminate the units of measurement, enabling you to more easily compare data from different places (Normalized Function, Normalized Data and Normalization, Glen). This kind of normalization also reduces computation time.
* References:
Jason Brownlee. "How to Perform Feature Selection with Categorical Data" from https://machinelearningmastery.com/using-normalization-layers-to-improve-deep-learning-models/
Stephanie Glen. "Normalized Function, Normalized Data and Normalization" from StatisticsHowTo.com, https://www.statisticshowto.com/types-of-functions/normalized-function-data-normalization/

- The squared distance may be used to measure item similarity provided that their features have the same length.
SD = Σ(l=1, n) (xk - xi)^2
where:
xk = Features of the reference item.
xi = Features of the item being used for comparison, i.e. a match candidate.

This function is also written as:
|| xk - xi ||^2

- Collaborative filtering performs bad with a cold start. If there are few items or few users of a product, the predictions will not be accurate even when compared to human guesses. Additional information like demographics or user device are not always easy to integrate with collaborative filtering.

Question:
How a machine learning model estimates unevenly correlated features.
https://stats.stackexchange.com/questions/621821/how-does-a-machine-learning-model-estimate-unevenly-correlated-features/621826?noredirect=1#comment1157530_621826

There are a number of models you could use for such a problem.

You could simply use linear regression with interaction terms, where different features would interact with watching time. This is a model that can detect a relation that differs for specific subgroups. Notice that with such a model, you don't need to discretize the data into intervals, you could use the watching time as-is.

Stagewise regression would lead you to build a regression model where you would have distinct regression lines conditionally on some features. This would be useful if you have some prior knowledge about the data and want to define a model that explicitly states how to split the data for separate regression lines.
If you don't know how the data is clustered, but you know that there are several clusters where each has its own regression line, you could use latent-class regression, a model that combines cluster analysis and regression.

A regression tree would split the data into many groups and predict means per each group. If you want to take into account multiple interactions between the features and use a non-parametric model, this may be one possibility.

Finally, you could use something like a neural network that will by itself figure out the interactions in your data.

@@@
Content-based Filtering
- Content-based filtering matches the features of an item to the features of a user. The vectors describing the user and the item or product may be different lengths. Content-based filtering involves operations on these two vectors. Collaborative filtering finds parameters for user data to predict a product characteristic vector. Afterward, the model can be used to predict or learn parameters for product characteristics to find a good match.

- The final vectors for content-based filtering have to be processed so that they are the same length. After solving for the parameters of a certain user or product, matches can be made by calculating the distance between reference output from a product or user and actual products or users.

- To get around the computation costs, it is better to perform an infrequent and slow retrieval step where large numbers of items or users are matched. Afterward, they are ranked based on closeness to the reference user or product.

@@@
Principal Component Analysis
- Principal Component Analysis (PCA) is an unsupervised algorithm used to reduce the number of input features for a machine learning model. PCA may reduce the number of features by detecting a new axis or engineered feature to represent two other features without losing information.

- To perform PCA, the features have to be normalized to have a mean of zero. The features should also be scaled to avoid differences in value due to measurement scales. Usually, z-score normalization is used to prepare data for PCA.

- PCA attempts to preserve as much of the original variance among the features to be "projected" onto the axis.

- In certain cases, especially when doing PCA on two features, visualizing the result thru PCA is a viable tactic. In rare cases, PCA may compress your data and reduce the raw amount of data transferred or processed. PCA may still reduce the accuracy of a model. 

++++++++++++++++++++++
Reinforcement Learning

@@@
Bellman Equation
Q(s, a) = R(s) + γ max(Q(s', a'))
where:

Q = Reward for current state after executing a once.
a = Current action.
s = Current state.
s' = State after current action.
a' = Action for future state.
γ = Gamma symbol denoting "discount" or weight.

- To summarize, this equation finds the action that gives the maximum current reward R(s) plus reward (Q(s', a')) for the state after executing a once, assuming that the "agent" behaves optimally after the current action (a).

- To add the possibility of a "misstep" into an unintended state may be accounted for. Use the average or expected value for the next state (Q(s', a')).

Q(s, a) = R(s) + γE[max(Q(s', a'))]
where:
E[...] = Expected or average value.

@@@
Continuous State Spaces
- A neural network may be trained to give the correct state and optimal action. Target values have to be generated to teach the correct Q(s, a). Since the Q(s', a') is uncertain, it may be set to a random value in the training set. The output of the neural network would be the probability or weight for each possible action.

Training Process Summary:
1. Take random actions and record the state. Even the Q(s', a') is random.
2. Find training examples using all or a portion of the experiment. The convention is to use a certain number of the most recent examples as the replay buffer.
3. Train the network on these experiments.
4. Prepare to repeat the process. Set the Q(s, a) to the newly calculated values. The next round will not be randomly initialized.

The Q(s', a') may be set to one value for all training examples during the first run. This simulates giving all possible actions or states equal value. Q(s', a') may also be calculated backward after reaching the terminal state. Then, the estimates of each sample Q(s', a') may be changed before starting a new cycle of generating new training examples. Some algorithms set Q(s', a') to random values on the first run. Others estimate Q(s', a') based on a certain range of recorded states.

A Stack Exchange article suggested taking the aggregated value of all rewards including the terminal state. That can be used to set Q(s', a').
https://stats.stackexchange.com/questions/416661/reward-attribution-in-deep-q-learning-and-texas-holdem-poker/416681#416681

Another article suggested to set all Q(s', a') to zero or -1.
https://stats.stackexchange.com/questions/337781/can-someone-please-explain-the-target-update-for-deep-q-learning/337790#337790

This article from Purdue University suggested building a Q-table and then looking up the reward:
https://engineering.purdue.edu/DeepLearn/pdf-kak/Reinforcement.pdf

Epsilon-greedy Policy
- While the algorithm is still running and is not at the end or terminal state, pick the action that maximizes Q(s', a') with near-one probability, e.g. 0.98. Pick a random action with the inverse probability ε, e.g. 0.02 times. Taking the random action ε percentage of times is also referred to as an exploration step. The greedy or exploitation step is the step that maximizes Q(s, a).

- In some cases, starting with a high ε and gradually reducing it may help the neural network explore many alternatives earlier and then maximize Q(s, a) later.

- Training can be sped up by performing gradient descent on different subsets or batches of data. In other words, the algorithm will only use parts of the replay buffer.

- To prevent random and sudden changes to the parameters, soft updates can be used instead of Q = Q(new). To perform a soft update, a large proportion of the new value will be taken from the old values. The inverse proportion will be taken from the new parameter values. Soft updates usually induce faster convergence thru gradient descent.

