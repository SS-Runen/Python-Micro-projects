++++++++++++++++++
General Guidelines

- When testing a formula or procedure, try the process using some input. For equations, try to find a trend in the results relative to the input. For ML algorithms, run limited tests on groups or sets with at least thirty samples. Depending on the situation, a control may be needed or the same data has to be used for different processes.

- To start Spyder in Ubuntu Linux:
conda activate spyder-env
spyder

Here, "spyder-env" is the name of your Conda environment. This is the default name and it may be changed.

- A plugin is needed to open and edit notebooks in Spyder:
conda install spyder-notebook -c conda-forge

+++++++++++++++++
Linear Regression

For a cost function J with parameters w and b, J(w, b), continuously update w and b to minimize J.
w = w - α (∂/∂w)J(w,b)
and
b = b - α (∂/∂b)J(w,b)
Where:
α = Learning rate. This is a decimal value between 0 and 1. It functions as a multiplier to the amount of change.
(d/dw)J(w,b) = This entire term represents the value of the partial derivative of the function J with parameters w and b. The term "d" indicates to change the value of w when looking for the derivative and to keep other values constant.

* A derivative is the rate of change of a function relative to a variable. A derivative may be noted as f' or as d/dx. A partial derivative may be noted as ∂/∂x or f. The term x can be any variable. Calculating a derivative involves finding the slope of a point in a line using the properties of tangents, limits, and triangle trigonometry.
* The update operations of w and b have to be done at the same time and in step. When performing the descent, the current/old values should be used as input to J. The updated values will only be used in the next iteration.

+++++++++++++++++++
Logistic Regression

Sigmoid Function
- a.k.a Logistic Function. It outputs values between zero and one given z.
g(z) = 1 / (1 + e^-z)

- A linear or polynomial function is the input (z) to a logistic/sigmoid function. The result of a logistic function is the probability of a positive result, i.e. the sigmoid function gives the probability that the target characteristic is present for the sample/vector x.
f(w, b) = P(y = 1 | x; w, b)

Decision Boundary
- The decision boundary is the value at which the probability between g(z) = 1 and g(z) = 0 is equal or neutral. g(w,x) = w1x1 +...wnxm = 0. The decision boundary may be calculated by substituting values into the input equation and then solving for or simplifying them. 

Logarithm
- A logarithm is the exponent or power to which a base must be raised to yield a given number. E.g. the logarithm of 8 with base 2 is 3. Two must be raised to the exponent three to yield eight.

Simplified Cost Function for Logistic Regression
- Refer to Google Drive notes. This function is convex (only has one global minimum) and uses the statistical principle of maximum likelihood.

+++++++++++++++++++++++++++++++++++++++
Gradient Descent with Linear Regression

These are the expanded formulas for a cost function used in single-variable linear regression. Here, the function f with parameters w and b - f(w,b) - is a linear function.
w = w - α * (1/m) * Σ(f<-w,b(wx^i + b) - y^i) x^i
b = b - α * (1/m) * Σ(f<-w,b(wx^i + b) - y^i)

* Due to the rules of calculus, the x^i term happens to be removed when calculating the update to b.

- A property of gradient descent cost functions for linear regression is that they do not have multiple local minima. This kind of function is called a convex function, i.e. a function with only one global minimum.

Convergence Checking
- Check if the error or cost function decreases by a certain amount, ε. Compare the error optimization of different learning rates (α) over a small amount of runs (e.g. 30) and gradually change α.

Feature Engineering for Regression
- Features may be removed automatically by the model. Another way is to use domain knowledge to transform or combine data into new features and compare their performance to a certain baseline or "control" set of features. You may also compare the effect of new or aggregated features to the separate source features.

Polynomial Regression
- You may derive a new feature from x by taking its various powers - usually the second or third - or taking x' square root. This may not be applicable to some features with negative values. For negative values, it may be useful to transform the absolute value and then multiply it to a negative value as part of the transformation process.

Loss Functions and Cost Functions
A loss function is calculated per set of parameters and input. This is equivalent to calculating using the data of one row. A cost function uses the principles of derivatives and polynomials to find the slope of the entire data set. The cost function uses the average of all results in the data set to determine the general direction parameters need to be shifted.

+++++++++++++++
Feature Scaling

Z-score normalization - Use the z-scores as x-values.
x = (x - μ) / σ

Min-max normalization
x = x / (max(vectorX))

Mean normalization
x = (x - μ) / (max(vectorX) - min(vectorX))

- If certain features have very large or very small x-values, the gradient descent model may take longer to reach a low-value cost function. The user has low control over the amount of change to a parameter in the early stages of the cost function optimization. Values with an uneven scale may force the model to "bounce" around large ranges and take longer to minimize error.

- When normalizing, it is recommended to have values within a small countable negative and positive range to retain magnitude and direction versus some reference point.

???
If your input Z-score, min-max, and mean change constantly, what are the proper scaling or normalization techniques? For stock data, the average and min-max change week to week. Is it good to pick an arbitrary mean, min-max, or other reference point for all data?

++++++++++++++++++++++++++++
Overfitting and Underfitting

- If a model fails to capture or reflect the relationships between parameters and input strongly enough, its predictions will not change properly with respect to new or real-world input. This is underfit model is said to have high bias, similar to having a "preconception" and ignoring data that goes against the preconception.

- When a model is overfitted, it responds too strongly and too specifically to training data. Due to the mathematics of the model, any slight deviation of the input from the training data will cause very inaccurate predictions. Slightly different data sets can give very different results, so an overfit model is said to have high variance.

- A good model adjusts predictions based on input without giving erroneous results when presented real-world data or proper data from the same population. This model is a "generalized" model.

- Overfit may be caused by excess parameters that hint at relationships which don't exist in the population. Excess parameters may also cause underfit due to noise. The model could miss the proper cost function minimization parameters since it does not have good feedback.

@@@
Avoiding or Solving Overfitting

- Collect more samples. Make sure as many samples as possible are representative of your population.

- Remove some features. A disadvantage of reducing features is that some nuance may be removed. Testing and other kinds of analysis are needed to remove features properly.

- Regularization. Reduce certain or all feature values to lessen their effect on the chosen parameters. The reduction calculation has to be the same for all features. A regularization parameter (λ) has to be chosen.
The following term may be added to the simplified logistic regression cost function to regularize the input.

λ/2m * Σ(j=1 n) w[j]^2
Where:
n = Number of features.
j = Index for the row/horizontal vector. Index j points to a feature parameter.
m = Number of rows/horizontal vectors.
w = Input or feature value.

+++++++++++++++++++++++++++++++++++
Matrix Operations and Vectorization

- The dot product of two vectors x and y is equivalent to the dot product of transpose(x) and y.

- You may only perform a dot product on vectors with the same length.

@@@
Matrix Multiplication Rules

- To multiply matrices, the first matrix must have the same number of columns (vertical vectors) as the other matrix' rows. E.g. three by two and two by four. To multiply a twelve by n and m by twelve matrix, the m by twelve matrix has to be the first input of the operation. This is a side-effect of the dot-product rule for multiplying vectors.

- The result of a matrix dot product will have the same number of rows as the first matrix and the same number of columns as the second.

- In general, matrix multiplication is NOT commutative. The order of the matrices is significant in matrix multiplication. Only certain edge cases result in commutative matrix multiplications.

++++++++++++++++++++++++++++++++
Basic Artificial Neural Networks

@@@
Activation Functions

- For binary classification problems, the sigmoid function is usually best for the final or "output" layer. The network will predict the probability of y = 1 or 0. The decision boundary (values where P(y=0) = P(y=1)) or an arbitrary probability may be used as a threshold for activation.

- Problems that fit the criteria of linear regression often need the linear activation function for the output layer. It is recommended to avoid using the linear activation function for hidden layers. If a linear or sigmoid function is used at the output layer, the results will be similar to ordinary linear or logistic regression.

- If the ground truth or source of truth (y) should only have positive values, use the Rectified Linear Unit (ReLU) function for the output layer.

*Note: The activation function of the output layer is not always the same as the hidden layer/s. The most common hidden layer activation function is the ReLU.

ReLU - g(z) = max(0, z). This function is slightly faster to compute than the sigmoid function. More important for speed, the sigmoid function has two areas where the output is flat when graphed. When using gradient descent, the computations for those values will change slowly. The ReLU only has one area where it is flat. If done properly, the ReLU will be computed faster without losing accuracy.

- SoftMax
Soft Max Loss Function = -log a(j) if y = j

The Softmax activation function computes the probability of each label versus the cumulative probability of all labels. For each output layer neuron or unit output a, the Softmax function g is calculated using the probabilities of each class label.
a1 = g(z1,z2,...zn)

Thus:
g(z1) = (e^z1) / (e^z1) + (e^z2) +...(e^zn)
...
g(zn) = (e^zn) / (e^z1) +...(e^zn)

@@@
Convolutional Neural Network
- A Convolutional Nueral Network (CNN) has units or neurons that only process part of the previous layer's output. These units will only process a section of the input data. It can compute results faster and reduce overfitting. The data or input for each neuron may overlap with other neurons. For images, it could mean overlapping coverage of an area. For time-series data, the time boundaries of the neurons may overlap. There, the next neuron has some idea of earlier or later data.

ADAM
- Adaptive Moment Estimation changes the learning rate for each parameter. It also adjusts the learning rate based on the direction and amount of change in the computed adjustment. As of July 06, 2023, A. Ng. described ADAM as the defacto optimization algorithm for neural networks.

- Back-propagation and Forward-propagation
Back-propagation using a computational graph takes N(nodes) + P(parameters) resources versus N * P during forward prop.
My understanding is that instead of calculating the derivative of J with respect to each parameter, the derivative is calculated at the end for one parameter. That derivative is used to calculate the derivative of other parameters without substituting all other parameters and x-values.

++++++++++++++++
Model Evalutaion

- Divide your training data into two representative sets. One will be used to train and the other will stand in for unknown test data. The convention is to divide train and test sets seventy to thirty. Extreme differences between the model error during training and the model error processing the test function is a sign of overfitting.

- The lowest test set error is not always a sign of the best parameters for a machine learning algorithm. Even if a test set error is low, it is still possible that the model happened to overfit to the test set. One solution is to add a third set to measure accuracy and pick a model before evaluating using the test set. The convention is 60-20-20. The cross-validation set is also called the development set.

@@@
Performance Baselines, Bias, and Variance

- If possible, benchmark model performance against human performance.

- Competing or standard algorithms may also be used as a baseline for performance, variance, and bias. The same training, cross-validation, and test data must be used for all models. To get the average train-test or train-cross-validation error difference, several different splits of data will have to be used. Process the average error difference.

- The training error is expected to increase as more data is used, eventually resembling a straight line. The cross-validation error is expected to decrease as training data increases. The graph of the cross-validation error will also straigten out as it approaches zero. Steadily increasing the train data with different sizes of subsets is usually too resource-intensive to be practical.

- Large neural networks are usually low-bias machines. Increasing the number of layers or units both reduce bias. For certain reasons, regularization can prevent large neural networks getting high variance.

Error Analysis
- In some cases, manually analyzing the inputs where the model gave the wrong answer is a good technique. Classify and describe possible patterns or markers.

Adding Data
- You may add more data similar to input that the model usually gets wrong.
- Certain cases benefit from data augmentation. Modifying or transforming data has to be consistent with the real-life input and use of the model. Rotating letters and adding background noise to speech audio are good examples.

Transfer Learning
- Transfer Learning refers to using an existing model used in a similar problem to train on your current data. The model input types should be the same. The idea is that certain generalized parameters could be learned and maintained. For example, image classification tasks with very different data might both require parameters to ignore empty space. The given example is image recognition of animals and people vs. digit recognition. If data for one problem is scarce, take the model with larger data. Either keep its hidden layer parameters and change the input and output layers or just its output layer to match your problem.

@@@
Skewed Data Sets
- For data sets with isolated but important cases, plain accuracy is not a good metric. For example, rare medical conditions have be diagnosed accurately even if their input values are outliers. For continuous output, the input data where the model has a high error metric should be analyzed, whether thru categorization or statistical analysis.

- Precision: Precision refers to the ratio of correct positive predictions to total positive predictions. True positives vs. predicted positives.
Precision = ( true_positives / (true_positive_predictions + false_positive_predictions)).

- Recall: Recall is the ratio of correctly predicted positives and actual positives. True positives vs. actual positives.
Recall = true_positives / true_positives + false_negatives.

- F1 Score. This calculation takes a weighted average where the smaller value's effect is increased. This is better at measuring precision vs. recall since if either one is high, it can "hide" defects. The F1 score equation may be referred to as the "harmonic mean of precision and recall (P and R)."
F1 = 1 / (0.5 * ((1/Precision) + (1/Recall)))
Alternative:
F1 = 2 * ((P*R) / (P+R)) 

++++++++++++++
Decision Trees

- When deciding on criteria to split a node, maximize the purity or homogenity of the split groups. The increase in purity is referred to as "information gain."

- Entropy
E = -p1 log2(p1) - (1 - p1)log2(1-p1)
where:
p1 = Proportion of true or positive labels.

The logarithm has a base of two so that the output is always between zero and one. Entropy is used to measure purity. The higher the entropy, the more mixed or non-homogenous the split.

- Entropy is best used with a weighted average or coefficient. A group with few examples and high purity could skew the results. For each decision node, multiply the proportion of input samples per group with the group entropy. Add the two results to get the overall node entropy.

- To calculate the information gain/entropy reduction for decision nodes (nodes beyond the root node), find the difference between the entropy of the root node and the entropy of the decision node. Information gain may be a better metric for split quality than plain entropy.

Information gain from a node:
IG = H(p1r) - (wl * H(p1l) + wr * H(p1r))
where:

H(p1r) = Entropy of input before splitting at the node. The input here is the proportion of positively labelled data.
wl = Proportion of input split into the left node.
wr = Proportion of input split into the right node.
p1l = Proportion of positively labeled examples in the left node.
H(p1l) = Entropy of left split.
p1r = Proportion of positively labeled examples in the right node.
H(p1r) = Entropy of right split.

- When using one-hot encoding on a decision tree, create k new features/columns for k number of features, not k-1 for linear regression dummy values.

- When splitting continuous values, use the information gain to pick a threshold. Other analysis methods may also be used as comparison or to complement the analysis. The central tendencies of each group or normal distribution thresholds are good points to consider.

- The same feature may be used as the split criteria in both left and right sides.

- When using a decision tree to output a continuous value, reduce the total weighted average variance of the target value for the split groups. The reduction in variance may be used as a split quality metric. The greater the reduction in variance, the better the split.

- A single tree is very sensitive to changes in data, whether the input is categorical or continuous. Decision trees are best used together as decision tree ensembles. Different splits may be created based on multiple samplings with replacement. The conventional number of decision trees in an ensemble is around one hundred.

- Randomizing the subset of features to be used as candidates for split criteria increases accuracy. Out of n features, choose a set of k features as candidates for split criteria. The value of k should be less than n. This forces the exploration of different possible variations in the data.

XGBoost
- Part of XGBoost is a mechanism to increase the likelihood that misclassified samples will be picked during input sampling. XGBoost (Extreme Gradient Boosting) also has built-in regularization, though input may still need to be normalized.

- In general, decision trees work well with tabular data. The input data and prediction values may be categorical or continuous. Decision trees perform poorly on unstructured data such as text, images, and audio. Decision trees are usually faster to train compared to neural networks with similar performance. Small sections of decision trees might be human-readable.

* Neural networks may also do well with structured, unstructured, and mixed data. Transfer learning is not applicable to decision trees. As of 2023, neural networks are easier to string together than decision trees.

++++++++++
Clustering

@@@
K-means Clustering
- K-means clustering initializes k clusters and assigns data points based on their distance or "difference" compared to the cluster. Next, k-means will assign the centroid values to the average of each parameter using the current members of the cluster. K-means will minimize the distance or "distortion" within clusters by adjusting the centroid.

K-means Cost Function, a.k.a Distortion Function:
J(c1...cm, μ1...,μk) = (1/m)*(Σ||xi - μ(c^i)||^2

where:
c1...cm = Clusters 1 to m.
μ1...,μk = Centroids 1 to k corresponding to clusters 1 to m.
xi = Input data x at index i.
μ(c^i) = Notation for cluster centroid to which xi is assigned.

Initializing K-means
- Picking one random data point as the value for each data point may help avoid empty clusters. Points may also be selected by sorting the data and selecting data points at certain intervals.

- Running multiple trials of K-means is a viable option. If there are multiple results, pick the one with the lowest cost function J(c1...cm, μ1...,μk).

- Choosing k-clusters to minimize J does not give the best number of clusters. It usually gives the highest possible number of clusters without increasing J, not necessarily the most appropriate cluster. Minimizing J does not guarantee a truly significant or important difference between clusters. Manual data analysis and domain knowledge have to be included in the process to pick the number of clusters.

